{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aa3a0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f7cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the mysql database credentials\n",
    "host = os.getenv(\"host\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "database = os.getenv(\"database\")\n",
    "port = os.getenv(\"port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92f92adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3306'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a287d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def connect_to_database():\n",
    "    \"\"\"Establish connection to MySQL database\"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host,\n",
    "            database=database,\n",
    "            user=user,  # Update with your credentials\n",
    "            password=password\n",
    "        )\n",
    "        return connection\n",
    "    except Error as e:\n",
    "        print(f\"Error connecting to MySQL: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_all_candidates():\n",
    "    \"\"\"Fetch all candidate data from joined tables\"\"\"\n",
    "    connection = connect_to_database()\n",
    "    if not connection:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        query = '''\n",
    "        SELECT ur.resumeid, p.name, p.location, p.email, p.phone,\n",
    "               e.degree, e.major, e.school, e.startdate, e.enddate, e.grade,\n",
    "               we.company, we.role, we.startdate AS work_startdate, we.enddate AS work_enddate, \n",
    "               GROUP_CONCAT(s.skillname) as skills, we.description, \n",
    "               we.locationcity, we.locationcountry, ur.ocrtext, \n",
    "               mu.name AS user_name, mu.notes, mu.preferredrole, mu.workavailability, \n",
    "               mu.fulltimestatus, mu.fulltimeavailability, mu.fulltimesalary,\n",
    "               mu.fulltimesalarycurrency, mu.parttimesalary, mu.summary\n",
    "        FROM UserResume ur\n",
    "        JOIN Education e ON e.educationId = ur.resumeId\n",
    "        JOIN WorkExperience we ON we.workExperienceId = ur.resumeId\n",
    "        JOIN PersonalInformation p ON p.personalInfromationId = ur.resumeId\n",
    "        JOIN mystartup_users mu ON mu.userid = ur.resumeid\n",
    "        JOIN mystartupUserSkills ms ON ms.userId = ur.resumeid\n",
    "        JOIN skills s ON s.skillid = ms.skillid\n",
    "        GROUP BY ur.resumeid\n",
    "        ORDER BY ur.resumeid\n",
    "        '''\n",
    "        cursor.execute(query)\n",
    "        records = cursor.fetchall()\n",
    "        return records\n",
    "    except Error as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fdddfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Testing database connection and data fetching\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 1\n",
    "print(\"Phase 1: Testing database connection and data fetching\")\n",
    "candidates_data = fetch_all_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef6d23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97db38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total candidate in database:- 5\n",
      "Sample candidate: Rahul Sharma\n"
     ]
    }
   ],
   "source": [
    "if candidates_data:\n",
    "    print(f\"total candidate in database:- {len(candidates_data)}\")\n",
    "    print(\"Sample candidate:\", candidates_data[0]['name'] if candidates_data else \"No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e44f19",
   "metadata": {},
   "source": [
    "### Profile-summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df9369d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_candidate_profile_text(candidate):\n",
    "    \"\"\"Create comprehensive profile text for embedding generation\"\"\"\n",
    "    profile_parts = []\n",
    "    \n",
    "    try:\n",
    "        # Personal and Role Information\n",
    "        profile_parts.append(f\"Name: {candidate['name']}\")\n",
    "        profile_parts.append(f\"Preferred Role: {candidate['preferredrole']}\")\n",
    "        \n",
    "        # Parse location JSON\n",
    "        if isinstance(candidate['location'], str):\n",
    "            location = json.loads(candidate['location'])\n",
    "        else:\n",
    "            location = candidate['location']\n",
    "        profile_parts.append(f\"Location: {location.get('city', '')}, {location.get('state', '')}, {location.get('country', '')}\")\n",
    "        \n",
    "        # Education Background\n",
    "        profile_parts.append(f\"Education: {candidate['degree']} in {candidate['major']} from {candidate['school']}\")\n",
    "        profile_parts.append(f\"Academic Grade: {candidate['grade']}\")\n",
    "        \n",
    "        # Work Experience\n",
    "        profile_parts.append(f\"Current/Recent Role: {candidate['role']} at {candidate['company']}\")\n",
    "        profile_parts.append(f\"Work Location: {candidate['locationcity']}, {candidate['locationcountry']}\")\n",
    "        profile_parts.append(f\"Work Description: {candidate['description']}\")\n",
    "        \n",
    "        # Skills\n",
    "        profile_parts.append(f\"Technical Skills: {candidate['skills']}\")\n",
    "        \n",
    "        # Availability and Compensation\n",
    "        profile_parts.append(f\"Work Availability: {candidate['workavailability']}\")\n",
    "        profile_parts.append(f\"Full-time Status: {candidate['fulltimestatus']}\")\n",
    "        profile_parts.append(f\"Expected Salary: {candidate['fulltimesalary']} {candidate['fulltimesalarycurrency']}\")\n",
    "        \n",
    "        # Resume OCR and Summary\n",
    "        profile_parts.append(f\"Resume Content: {candidate['ocrtext']}\")\n",
    "        profile_parts.append(f\"Professional Summary: {candidate['summary']}\")\n",
    "        profile_parts.append(f\"Additional Notes: {candidate['notes']}\")\n",
    "        \n",
    "        return \" | \".join(profile_parts)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating profile for {candidate.get('name', 'Unknown')}: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10a41fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_profile_texts(candidates_data):\n",
    "    \"\"\"Generate profile texts for all candidates\"\"\"\n",
    "    profile_texts = []\n",
    "    candidate_ids = []\n",
    "    \n",
    "    for candidate in candidates_data:\n",
    "        profile_text = create_candidate_profile_text(candidate)\n",
    "        if profile_text:\n",
    "            profile_texts.append(profile_text)\n",
    "            candidate_ids.append(candidate['resumeid'])\n",
    "    \n",
    "    return profile_texts, candidate_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ccb1f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: Testing profile text generation\n",
      "Generated 5 profile texts\n",
      "Sample profile text (first 200 chars): Name: Rahul Sharma | Preferred Role: Backend Developer | Location: Mumbai, Maharashtra, India | Education: Bachelor of Science in Computer Science from IIT Delhi | Academic Grade: 8.5 | Current/Recent...\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 2\n",
    "print(\"\\nPhase 2: Testing profile text generation\")\n",
    "if candidates_data:\n",
    "    profile_texts, candidate_ids = generate_all_profile_texts(candidates_data)\n",
    "    print(f\"Generated {len(profile_texts)} profile texts\")\n",
    "    print(f\"Sample profile text (first 200 chars): {profile_texts[0][:200]}...\" if profile_texts else \"No profiles generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74f58093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name: Rahul Sharma | Preferred Role: Backend Developer | Location: Mumbai, Maharashtra, India | Education: Bachelor of Science in Computer Science from IIT Delhi | Academic Grade: 8.5 | Current/Recent Role: Software Engineer at Tata Consultancy Services | Work Location: Mumbai, India | Work Description: Worked on backend systems and REST APIs using Java and Spring Boot. | Technical Skills: Java,Spring Boot,REST APIs,SQL,AWS,Docker,Microservices | Work Availability: Full-time | Full-time Status: Available | Expected Salary: 5000 USD | Resume Content: Software Engineer with 3+ years experience in Java Spring Boot microservices REST APIs backend development MySQL PostgreSQL Docker Kubernetes AWS cloud deployment CI/CD Jenkins Git version control agile methodologies | Professional Summary: Experienced backend developer with 3+ years at TCS, specializing in Java Spring Boot microservices and cloud deployment | Additional Notes: Strong backend developer with TCS experience, excellent problem-solving skills, good team player',\n",
       " 'Name: Priya Patel | Preferred Role: Data Analyst | Location: Hyderabad, Telangana, India | Education: Bachelor of Technology in Electrical Engineering from NIT Trichy | Academic Grade: 8.2 | Current/Recent Role: Data Analyst at Google | Work Location: Hyderabad, India | Work Description: Analyzed user data to generate actionable insights for product improvements. | Technical Skills: Python,Data Analysis,SQL,Machine Learning,Tableau | Work Availability: Full-time | Full-time Status: Available | Expected Salary: 6000 USD | Resume Content: Data Analyst with expertise in Python pandas numpy scikit-learn machine learning data visualization Tableau PowerBI SQL BigQuery statistical analysis A/B testing data mining predictive modeling | Professional Summary: Senior data analyst from Google with expertise in Python, machine learning, and large-scale data processing | Additional Notes: Google data analyst with exceptional analytical skills and machine learning expertise',\n",
       " 'Name: Amit Kumar | Preferred Role: Full Stack Developer | Location: Pune, Maharashtra, India | Education: Master of Science in Data Science from BITS Pilani | Academic Grade: 9.0 | Current/Recent Role: Systems Engineer at Infosys | Work Location: Pune, India | Work Description: Developed web applications and maintained internal tools. | Technical Skills: JavaScript,React,Node.js,SQL,TypeScript,MongoDB | Work Availability: Both | Full-time Status: Available | Expected Salary: 4500 USD | Resume Content: Full-stack Systems Engineer with experience in JavaScript TypeScript React.js Node.js Express.js MongoDB PostgreSQL HTML5 CSS3 responsive design RESTful APIs GraphQL web development modern frameworks | Professional Summary: Full-stack systems engineer with experience in React, Node.js, and modern web development practices | Additional Notes: Full-stack developer with Infosys background, strong in modern web technologies',\n",
       " 'Name: Sneha Gupta | Preferred Role: Product Manager | Location: Bangalore, Karnataka, India | Education: Bachelor of Arts in Economics from Delhi University | Academic Grade: 7.8 | Current/Recent Role: Product Manager at Microsoft | Work Location: Bangalore, India | Work Description: Led cross-functional teams to launch productivity features in Office 365. | Technical Skills: Product Management,Business Analysis,Agile,Excel | Work Availability: Full-time | Full-time Status: Available | Expected Salary: 8000 USD | Resume Content: Product Manager with MBA background leading cross-functional teams product roadmap feature prioritization user research market analysis competitive analysis stakeholder management Office 365 productivity tools | Professional Summary: Senior Product Manager from Microsoft with MBA and experience in Office 365 product development and team leadership | Additional Notes: Microsoft Product Manager with MBA, excellent leadership and strategic thinking',\n",
       " 'Name: Vikram Singh | Preferred Role: Business Analyst | Location: Chennai, Tamil Nadu, India | Education: Master of Business Administration in Marketing from IIM Bangalore | Academic Grade: 8.9 | Current/Recent Role: Business Analyst at Amazon | Work Location: Chennai, India | Work Description: Managed business metrics and contributed to logistics optimization. | Technical Skills: Business Analysis,SQL,Data Analysis,Excel | Work Availability: Full-time | Full-time Status: Available | Expected Salary: 5500 USD | Resume Content: Business Analyst with experience in logistics optimization supply chain management business metrics KPI analysis process improvement data-driven decision making Excel advanced analytics business intelligence | Professional Summary: Experienced business analyst from Amazon specializing in logistics optimization and data-driven business improvements | Additional Notes: Amazon business analyst with strong optimization and process improvement skills']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a87dbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages first\n",
    "# !pip install sentence-transformers numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87054d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35a2b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_embedding_model():\n",
    "    \"\"\"Initialize the sentence transformer model\"\"\"\n",
    "    try:\n",
    "\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        print(\"Embedding model loaded successfully\")\n",
    "        return model\n",
    "    except ImportError:\n",
    "        print(\"Please install sentence-transformers: pip install sentence-transformers\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_embeddings(model, profile_texts):\n",
    "    \"\"\"Generate embeddings for profile texts\"\"\"\n",
    "    if not model:\n",
    "        return None\n",
    "    try:\n",
    "        embeddings = model.encode(profile_texts, convert_to_tensor=False)\n",
    "        return np.array(embeddings, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embeddings: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5105cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 3: Testing embedding generation\n",
      "Embedding model loaded successfully\n",
      "Generated embeddings shape: (5, 384)\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Phase 3\n",
    "print(\"\\nPhase 3: Testing embedding generation\")\n",
    "embedding_model = setup_embedding_model()\n",
    "if embedding_model and profile_texts:\n",
    "    embeddings = generate_embeddings(embedding_model, profile_texts)\n",
    "    if embeddings is not None:\n",
    "        print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "        print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "    else:\n",
    "        print(\"Failed to generate embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fadf0d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 384)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings),len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf87d75",
   "metadata": {},
   "source": [
    "### Metadata extraction from query:_- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab1e9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_candidate_metadata(candidate):\n",
    "    \"\"\"Extract structured metadata for filtering\"\"\"\n",
    "    try:\n",
    "        # Parse location\n",
    "        if isinstance(candidate['location'], str):\n",
    "            location = json.loads(candidate['location'])\n",
    "        else:\n",
    "            location = candidate['location']\n",
    "        \n",
    "        # Calculate experience years\n",
    "        work_start = datetime.strptime(str(candidate['work_startdate']), '%Y-%m-%d')\n",
    "        work_end = datetime.strptime(str(candidate['work_enddate']), '%Y-%m-%d')\n",
    "        experience_years = (work_end - work_start).days / 365.25\n",
    "        \n",
    "        # Extract skills list\n",
    "        skills_list = [skill.strip() for skill in candidate['skills'].split(',')]\n",
    "        primary_skills = skills_list[:3]  # First 3 as primary\n",
    "        \n",
    "        # Determine company type\n",
    "        big_companies = ['Google', 'Microsoft', 'Amazon', 'Apple', 'Meta', 'Netflix', 'Tesla']\n",
    "        company_type = 'MNC' if candidate['company'] in big_companies else 'Other'\n",
    "        \n",
    "        metadata = {\n",
    "            \"candidate_id\": candidate['resumeid'],\n",
    "            \"name\": candidate['name'],\n",
    "            \"preferred_role\": candidate['preferredrole'],\n",
    "            \"skills\": skills_list,\n",
    "            \"primary_skills\": primary_skills,\n",
    "            \"company\": candidate['company'],\n",
    "            \"company_type\": company_type,\n",
    "            \"location_country\": location.get('country', ''),\n",
    "            \"location_city\": location.get('city', ''),\n",
    "            \"work_availability\": candidate['workavailability'],\n",
    "            \"salary_usd\": float(candidate['fulltimesalary']) if candidate['fulltimesalary'] else 0,\n",
    "            \"salary_currency\": candidate['fulltimesalarycurrency'],\n",
    "            \"experience_years\": round(experience_years, 1),\n",
    "            \"education_level\": candidate['degree'],\n",
    "            \"is_remote_available\": 'remote' in candidate['workavailability'].lower(),\n",
    "            \"is_active\": candidate['fulltimestatus'] == 'Available',\n",
    "            \"last_updated\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata for {candidate.get('name', 'Unknown')}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dccf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_all_metadata(candidates_data):\n",
    "    \"\"\"Generate metadata for all candidates\"\"\"\n",
    "    metadata_list = []\n",
    "    \n",
    "    for candidate in candidates_data:\n",
    "        metadata = extract_candidate_metadata(candidate)\n",
    "        if metadata:\n",
    "            metadata_list.append(metadata)\n",
    "    \n",
    "    return metadata_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95f61a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 4: Testing metadata extraction\n",
      "Generated metadata for 5 candidates\n",
      "Sample metadata:\n",
      "  candidate_id: CAND001\n",
      "  name: Rahul Sharma\n",
      "  preferred_role: Backend Developer\n",
      "  skills: ['Java', 'Spring Boot', 'REST APIs', 'SQL', 'AWS', 'Docker', 'Microservices']\n",
      "  primary_skills: ['Java', 'Spring Boot', 'REST APIs']\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 4\n",
    "print(\"\\nPhase 4: Testing metadata extraction\")\n",
    "if candidates_data:\n",
    "    metadata_list = generate_all_metadata(candidates_data)\n",
    "    print(f\"Generated metadata for {len(metadata_list)} candidates\")\n",
    "    if metadata_list:\n",
    "        print(\"Sample metadata:\")\n",
    "        for key, value in list(metadata_list[0].items())[:5]:\n",
    "            print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fea3799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate_id': 'CAND001',\n",
       " 'name': 'Rahul Sharma',\n",
       " 'preferred_role': 'Backend Developer',\n",
       " 'skills': ['Java',\n",
       "  'Spring Boot',\n",
       "  'REST APIs',\n",
       "  'SQL',\n",
       "  'AWS',\n",
       "  'Docker',\n",
       "  'Microservices'],\n",
       " 'primary_skills': ['Java', 'Spring Boot', 'REST APIs'],\n",
       " 'company': 'Tata Consultancy Services',\n",
       " 'company_type': 'Other',\n",
       " 'location_country': 'India',\n",
       " 'location_city': 'Mumbai',\n",
       " 'work_availability': 'Full-time',\n",
       " 'salary_usd': 5000.0,\n",
       " 'salary_currency': 'USD',\n",
       " 'experience_years': 2.4,\n",
       " 'education_level': 'Bachelor of Science',\n",
       " 'is_remote_available': False,\n",
       " 'is_active': True,\n",
       " 'last_updated': '2025-06-22T14:40:24.163779'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de40990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend Developer\n",
      "Data Analyst\n",
      "Full Stack Developer\n",
      "Product Manager\n",
      "Business Analyst\n"
     ]
    }
   ],
   "source": [
    "for x in metadata_list:\n",
    "    print(x['preferred_role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "574173da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### phase 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e54de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_storage_structure(embeddings, metadata_list, candidate_ids):\n",
    "    \"\"\"Create a structure to store vectors with metadata\"\"\"\n",
    "    vector_storage = []\n",
    "    \n",
    "    for i, (embedding, metadata, candidate_id) in enumerate(zip(embeddings, metadata_list, candidate_ids)):\n",
    "        vector_entry = {\n",
    "            \"id\": candidate_id,\n",
    "            \"vector\": embedding.tolist(),\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        vector_storage.append(vector_entry)\n",
    "    \n",
    "    return vector_storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1117c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vector_storage(vector_storage, filename=\"candidate_vectors.json\"):\n",
    "    \"\"\"Save vector storage to file\"\"\"\n",
    "    try:\n",
    "        import json\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(vector_storage, f, indent=2)\n",
    "        print(f\"Vector storage saved to {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving vector storage: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8851f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 5: Testing vector storage setup\n",
      "Created vector storage with 5 entries\n",
      "Vector storage saved to candidate_vectors.json\n",
      "Vector storage saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 5\n",
    "print(\"\\nPhase 5: Testing vector storage setup\")\n",
    "if embeddings is not None and metadata_list and candidate_ids:\n",
    "    vector_storage = create_vector_storage_structure(embeddings, metadata_list, candidate_ids)\n",
    "    print(f\"Created vector storage with {len(vector_storage)} entries\")\n",
    "    \n",
    "    # Save to file\n",
    "    save_success = save_vector_storage(vector_storage)\n",
    "    if save_success:\n",
    "        print(\"Vector storage saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42ed1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5ea16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NER: named entitiy recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bccaec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy \n",
    "# !pip install nltk \n",
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cae9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Or a more robust model\n",
    "def extract_entities(user_query: str):\n",
    "    doc = nlp(user_query)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06816d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4 years', 'DATE'),\n",
       " ('MNC', 'ORG'),\n",
       " ('Indian', 'NORP'),\n",
       " ('C++', 'NORP'),\n",
       " ('max', 'PERSON'),\n",
       " ('500', 'CARDINAL'),\n",
       " ('USD', 'PRODUCT'),\n",
       " ('Java Spring Boot', 'WORK_OF_ART')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"I need a Python developer with 4 years of experience\",\n",
    "        \"Find me a full-time candidate with remote availability, having worked at big MNC\",\n",
    "        \"An Indian origin C++ developer with max salary 500 USD\",\n",
    "        \"Java Spring Boot developer with machine learning experience\"\n",
    " \"\"\"\n",
    "extract_entities(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b0280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "892e6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAMPLE QUERY FILTERATION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49423a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "def analyze_query(user_query: str) -> Dict:\n",
    "    \"\"\"Analyze user query to extract structured components\"\"\"\n",
    "    analysis = {\n",
    "        'skills': [],\n",
    "        'experience_years': None,\n",
    "        'max_salary': None,\n",
    "        'currency': 'USD',\n",
    "        'location': None,\n",
    "        'work_type': None,\n",
    "        'company_type': None,\n",
    "        'semantic_content': user_query.lower()\n",
    "    }\n",
    "    \n",
    "    # Extract skills\n",
    "    skill_patterns = {\n",
    "        'python': r'\\bpython\\b',\n",
    "        'java': r'\\bjava\\b',\n",
    "        'javascript': r'\\bjavascript\\b|\\bjs\\b',\n",
    "        'react': r'\\breact\\b',\n",
    "        'node': r'\\bnode\\.?js\\b',\n",
    "        'sql': r'\\bsql\\b',\n",
    "        'aws': r'\\baws\\b',\n",
    "        'spring boot': r'\\bspring\\s*boot\\b',\n",
    "        'machine learning': r'\\bmachine\\s*learning\\b|\\bml\\b',\n",
    "        'data analysis': r'\\bdata\\s*analysis\\b'\n",
    "    }\n",
    "    \n",
    "    for skill, pattern in skill_patterns.items():\n",
    "        if re.search(pattern, user_query.lower()):\n",
    "            analysis['skills'].append(skill)\n",
    "    \n",
    "    # Extract experience\n",
    "    exp_match = re.search(r'(\\d+)\\s*(?:years?|yrs?)\\s*(?:of\\s*)?experience', user_query.lower())\n",
    "    if exp_match:\n",
    "        analysis['experience_years'] = int(exp_match.group(1))\n",
    "    \n",
    "    # Extract salary\n",
    "    salary_match = re.search(r'(?:max|maximum|budget|salary).*?(\\d+)\\s*(usd|dollars?)', user_query.lower())\n",
    "    if salary_match:\n",
    "        analysis['max_salary'] = int(salary_match.group(1))\n",
    "    \n",
    "    # Extract location\n",
    "    if 'indian' in user_query.lower() or 'india' in user_query.lower():\n",
    "        analysis['location'] = 'India'\n",
    "    \n",
    "    # Extract work type\n",
    "    if re.search(r'full.?time', user_query.lower()):\n",
    "        analysis['work_type'] = 'Full-time'\n",
    "    elif re.search(r'part.?time', user_query.lower()):\n",
    "        analysis['work_type'] = 'Part-time'\n",
    "    \n",
    "    # Extract company type\n",
    "    if any(term in user_query.lower() for term in ['big', 'mnc', 'large', 'enterprise']):\n",
    "        analysis['company_type'] = 'MNC'\n",
    "    \n",
    "    return analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "202dc388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 6: Testing query analysis\n",
      "\n",
      "Query: I need a Python developer with 4 years of experience\n",
      "Analysis: {'skills': ['python'], 'experience_years': 4, 'max_salary': None, 'currency': 'USD', 'location': None, 'work_type': None, 'company_type': None, 'semantic_content': 'i need a python developer with 4 years of experience'}\n",
      "\n",
      "Query: Find me a full-time candidate with remote availability, having worked at big MNC\n",
      "Analysis: {'skills': [], 'experience_years': None, 'max_salary': None, 'currency': 'USD', 'location': None, 'work_type': 'Full-time', 'company_type': 'MNC', 'semantic_content': 'find me a full-time candidate with remote availability, having worked at big mnc'}\n",
      "\n",
      "Query: An Indian origin C++ developer with max salary 500 USD\n",
      "Analysis: {'skills': [], 'experience_years': None, 'max_salary': 500, 'currency': 'USD', 'location': 'India', 'work_type': None, 'company_type': None, 'semantic_content': 'an indian origin c++ developer with max salary 500 usd'}\n",
      "\n",
      "Query: Java Spring Boot developer with machine learning experience\n",
      "Analysis: {'skills': ['java', 'spring boot', 'machine learning'], 'experience_years': None, 'max_salary': None, 'currency': 'USD', 'location': None, 'work_type': None, 'company_type': None, 'semantic_content': 'java spring boot developer with machine learning experience'}\n"
     ]
    }
   ],
   "source": [
    "def test_query_analysis():\n",
    "    \"\"\"Test query analysis with sample queries\"\"\"\n",
    "    test_queries = [\n",
    "        \"I need a Python developer with 4 years of experience\",\n",
    "        \"Find me a full-time candidate with remote availability, having worked at big MNC\",\n",
    "        \"An Indian origin C++ developer with max salary 500 USD\",\n",
    "        \"Java Spring Boot developer with machine learning experience\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        analysis = analyze_query(query)\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"Analysis: {analysis}\")\n",
    "\n",
    "# Test Phase 6\n",
    "print(\"\\nPhase 6: Testing query analysis\")\n",
    "test_query_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd8676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17706877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def filter_candidates_by_metadata(vector_storage, query_analysis):\n",
    "    \"\"\"Filter candidates based on metadata criteria\"\"\"\n",
    "    filtered_candidates = []\n",
    "    \n",
    "    for candidate in vector_storage:\n",
    "        metadata = candidate['metadata']\n",
    "        \n",
    "        # Check salary constraint\n",
    "        if query_analysis.get('max_salary'):\n",
    "            if metadata['salary_usd'] > query_analysis['max_salary']:\n",
    "                continue\n",
    "        \n",
    "        # Check skills\n",
    "        if query_analysis.get('skills'):\n",
    "            candidate_skills = [skill.lower() for skill in metadata['skills']]\n",
    "            required_skills = [skill.lower() for skill in query_analysis['skills']]\n",
    "            if not any(skill in candidate_skills for skill in required_skills):\n",
    "                continue\n",
    "        \n",
    "        # Check location\n",
    "        if query_analysis.get('location'):\n",
    "            if query_analysis['location'].lower() not in metadata['location_country'].lower():\n",
    "                continue\n",
    "        \n",
    "        # Check work type\n",
    "        if query_analysis.get('work_type'):\n",
    "            if query_analysis['work_type'].lower() not in metadata['work_availability'].lower():\n",
    "                continue\n",
    "        \n",
    "        # Check company type\n",
    "        if query_analysis.get('company_type'):\n",
    "            if metadata['company_type'] != query_analysis['company_type']:\n",
    "                continue\n",
    "        \n",
    "        filtered_candidates.append(candidate)\n",
    "    \n",
    "    return filtered_candidates\n",
    "\n",
    "def semantic_search(query, filtered_candidates, embedding_model, top_k=5):\n",
    "    \"\"\"Perform semantic search on filtered candidates\"\"\"\n",
    "    if not filtered_candidates:\n",
    "        return []\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query], convert_to_tensor=False)[0]\n",
    "    \n",
    "    # Get candidate embeddings\n",
    "    candidate_embeddings = np.array([candidate['vector'] for candidate in filtered_candidates])\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity([query_embedding], candidate_embeddings)[0]\n",
    "    \n",
    "    # Get top-k results\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'candidate': filtered_candidates[idx],\n",
    "            'similarity_score': float(similarities[idx])\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def hybrid_search(user_query, vector_storage, embedding_model, top_k=5):\n",
    "    \"\"\"Perform hybrid search combining filtering and semantic search\"\"\"\n",
    "    # Analyze query\n",
    "    query_analysis = analyze_query(user_query)\n",
    "    print(f\"Query analysis: {query_analysis}\")\n",
    "    \n",
    "    # Filter by metadata\n",
    "    filtered_candidates = filter_candidates_by_metadata(vector_storage, query_analysis)\n",
    "    print(f\"Filtered to {len(filtered_candidates)} candidates\")\n",
    "    \n",
    "    # Semantic search\n",
    "    results = semantic_search(user_query, filtered_candidates, embedding_model, top_k)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d727096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae5d8e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 7: Testing similarity search\n",
      "Query analysis: {'skills': ['sql'], 'experience_years': None, 'max_salary': None, 'currency': 'USD', 'location': None, 'work_type': None, 'company_type': None, 'semantic_content': 'candidate with experience in sql'}\n",
      "Filtered to 4 candidates\n",
      "\n",
      "Search results for: 'Candidate with experience in SQL'\n",
      "1. Rahul Sharma - Backend Developer\n",
      "   Similarity: 0.440\n",
      "   Skills: Java, Spring Boot, REST APIs\n",
      "   Company: Tata Consultancy Services\n",
      "\n",
      "1. Priya Patel - Data Analyst\n",
      "   Similarity: 0.406\n",
      "   Skills: Python, Data Analysis, SQL\n",
      "   Company: Google\n",
      "\n",
      "1. Amit Kumar - Full Stack Developer\n",
      "   Similarity: 0.368\n",
      "   Skills: JavaScript, React, Node.js\n",
      "   Company: Infosys\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Phase 7\n",
    "print(\"\\nPhase 7: Testing similarity search\")\n",
    "if vector_storage and embedding_model:\n",
    "    test_query = \"Candidate with experience in SQL\"\n",
    "    search_results = hybrid_search(test_query, vector_storage, embedding_model, top_k=3)\n",
    "    \n",
    "    print(f\"\\nSearch results for: '{test_query}'\")\n",
    "    # for i, result in enumerate(search_results, 1):\n",
    "    for  result in search_results:\n",
    "        candidate = result['candidate']\n",
    "        score = result['similarity_score']\n",
    "        print(f\"{i}. {candidate['metadata']['name']} - {candidate['metadata']['preferred_role']}\")\n",
    "        print(f\"   Similarity: {score:.3f}\")\n",
    "        print(f\"   Skills: {', '.join(candidate['metadata']['primary_skills'])}\")\n",
    "        print(f\"   Company: {candidate['metadata']['company']}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78d988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa035cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
